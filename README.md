# Data Pipeline for Olympics 2024 Analysis
## Description
This projects focuses on building an end-to-end data pipeline that extracts raw data from Kaggle, processes and transforms it across three structured layers (Bronze, Silver and Gold), and stored it in Hadoop HDFS. The final transformed data is then loaded into a Snowflake data warehouse. The entire pipeline is oschetrated using Apache Airflow. For data visualization and reporting, Apache Superset is used to create interactive and informative dashboards.
## Table of contents
- [Architecture](#Architecture)
- [Overview](#Overview)
